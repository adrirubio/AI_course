* Full Walkthrough
  We start by importing these libraries:
  
  #+BEGIN_SRC python
  import torch
  import torch.nn as nn
  import torchvision
  import torchvision.transforms as transforms
  import numpy as np
  import matplotlib.pyplot as plt
  #+END_SRC
  
** The first step is to download the data
  
  - Train Data:
  
  #+BEGIN_SRC python
  train_dataset = torchvision.datasets.MNIST(
    # specify where to download the data, '.' means the current directory
    root='.',
    # indicates that this is the train dataset
    train=True,
    # converts the images into PyTorch tensors
    transform=transforms.ToTensor(),
    download=True)

  # see the training data:
  train_dataset.data
  #+END_SRC

  - Test Data:

  #+BEGIN_SRC python
  test_dataset = torchvision.datasets.MNIST(
    # specify where to download the data, '.' means the current directory
    root='.',
    # indicates that this is the test dataset by making train=False
    train=False,
    # converts the images into PyTorch tensors
    transform=transforms.ToTensor(),
    download=True)
  #+END_SRC  
    
  Note that nothing is downloaded because all the files were downloaded in the previous step
  
** Now it is time to build the model
   
   #+BEGIN_SRC python
   model = nn.Sequential(
    nn.Linear(784, 128),
    nn.ReLU(),
    nn.Linear(128, 10)
   )
   #+END_SRC

  Lets break down what each part of the code does:
  - "nn.Sequential": This is a sequential container from PyTorch's neural network module (torch.nn)
  - "nn.Linear(784, 128)": The first argument (784) is the size of each input sample, and the second argument (128) is the size of each output sample.
  - "nn.ReLU()": ReLU is a commonly used activation function in neural networks, especially in hidden layers 
  - "nn.Linear(128, 10)": This takes the 128-dimensional output from the previous layer and transforms it into a 10-dimensional output

**** Using the GPU
  - There is a need to make use of the GPU we know that GPU's use are useful for speeding up deep learning
  
  #+BEGIN_SRC python
  device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
  print(device)
  model.to(device)
  #+END_SRC
  
  - This code checks if a GPU is available otherwise it uses a CPU

**** Setting loss and optimizer
  - Here we set the loss and the optimizer
     
  #+BEGIN_SRC python
  # Loss and optimizer
  criterion = nn.CrossEntropyLoss()
  optimizer = torch.optim.Adam(model.parameters())
  #+END_SRC

**** Using a data loader
  - This is useful because it automatically generates batches in the training loop
  
  #+BEGIN_SRC python
  
  batch_size = 128
  train_loader = torch.utils.data.DataLoader(dataset=train_dataset, 
                                             batch_size=batch_size, 
                                             shuffle=True)
  
  test_loader = torch.utils.data.DataLoader(dataset=test_dataset, 
                                            batch_size=batch_size, 
                                            shuffle=False)
  #+END_SRC

  - "batch_size = 128": This sets the batch size to 128
  - "train_loader = torch.utils.data.DataLoader(...)": This creates a data loader for the training dataset.
  - "test_loader = torch.utils.data.DataLoader(...)": This creates a data loader for the testing dataset.
  - "dataset=train_dataset": This specifies that the data loader should use "train_dataset" (which we defined earlier)
  - "dataset=test_dataset": This specifies that the data loader should use "test_dataset" (which we defined earlier)
  - "shuffle=True/False": This should be "True" on the training dataset but "False" on the testing dataset.

** Training the model

   

   

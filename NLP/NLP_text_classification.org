** NLP for text classification
- This notebook is a custom NLP and some code will be new

*** imports
#+BEGIN_SRC python
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
import requests
import io
#+END_SRC

- Some of the imports are new

*** load the data
Here we load the data from a url:
#+BEGIN_SRC python
url = 'https://lazyprogrammer.me/course_files/spam.csv'
response = requests.get(url)
response.raise_for_status()  # Raise an error if download fails

df = pd.read_csv(io.StringIO(response.content.decode('latin-1')), encoding='latin-1')
#+END_SRC

*** prepare the file
Using pandas we can prepare the file to later create the dataset
#+BEGIN_SRC python
# drop unnecessary columns
df = df.drop(["Unnamed: 2", "Unnamed: 3", "Unnamed: 4"], axis=1)

# remame columns to something better
df.columns = ['labels', 'data']

# create binary labels
df['b_labels'] = df['labels'].map({'ham': 0, 'spam': 1})
#+END_SRC

*** map an integer to each token
- In this code we divide the file into df_train and df_test
#+BEGIN_SRC python
df_train, df_test = train_test_split(df, test_size=0.33)
df_train.shape, df_test.shape
#+END_SRC

This would print

#+BEGIN_SRC
((3733, 3), (1839, 3))
#+END_SRC

- In this next code padding is 0 so we start mapping integers to tokens from 1 onward
#+BEGIN_SRC python
# 0 = padding
idx = 1 # starts at 1
word2idx = {'<PAD>': 0}
#+END_SRC




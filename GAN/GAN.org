*** GAN model
This is the GAN model explained.

*** imports
Similar imports to always

#+BEGIN_SRC python
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torchvision.utils import save_image
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import os
#+END_SRC

*** loading the dataset
What this code does is make the images pytorch tensors and normalizes the tensors so that its pixel values range between -1 and +1. This is a common practice in training neural networks as it often helps in faster convergence.

#+BEGIN_SRC python
# looks weird, but makes pixel values between -1 and +1
# assume they are transformed from (0, 1)
# min value = (0 - 0.5) / 0.5 = -1
# max value = (1 - 0.5) / 0.5 = +1
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.5,),
                         std=(0.5,))])
#+END_SRC

For this model we are going to be using the MNIST dataset so we load it in like in the past.

#+BEGIN_SRC python
train_dataset = torchvision.datasets.MNIST(
    root='.',
    train=True,
    transform=transform,
    download=True)
#+END_SRC

*** data loaders
In this code we create the data loaders

#+BEGIN_SRC python
batch_size = 128
data_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                          batch_size=batch_size,
                                          shuffle=True)
#+END_SRC

*** defining the discriminator and the generator
Lets start by explaining the layers of the discriminator

#+BEGIN_SRC python
# Discriminator
D = nn.Sequential(
    nn.Linear(784, 512),
    nn.LeakyReLU(0.2),
    nn.Linear(512, 256),
    nn.LeakyReLU(0.2),
    nn.Linear(256, 1),
    # nn.Sigmoid()
)
#+END_SRC

Input Layer: ~nn.Linear(784, 512)~ - Takes a flattened 28x28 image (784 pixels) and outputs 512 features.
Hidden Layer 1: ~nn.LeakyReLU(0.2)~ - Adds non-linearity with a Leaky ReLU activation.
Hidden Layer 2: ~nn.Linear(512, 256)~ - Reduces the features from 512 to 256.
Hidden Layer 3: ~nn.LeakyReLU(0.2)~ - Another Leaky ReLU activation.
Output Layer: ~nn.Linear(256, 1)~ - Outputs a single value indicating real or fake.

#+BEGIN_SRC python
# Generator
latent_dim = 100
G = nn.Sequential(
    nn.Linear(latent_dim, 256),
    nn.LeakyReLU(0.2),
    nn.BatchNorm1d(256, momentum=0.7),
    nn.Linear(256, 512),
    nn.LeakyReLU(0.2),
    nn.BatchNorm1d(512, momentum=0.7),
    nn.Linear(512, 1024),
    nn.LeakyReLU(0.2),
    nn.BatchNorm1d(1024, momentum=0.7),
    nn.Linear(1024, 784),
    nn.Tanh()
)
#+END_SRC

Input Layer: ~nn.Linear(latent_dim, 256)~ - Takes a 100-dimensional noise vector and outputs 256 features.
Hidden Layer 1: ~nn.LeakyReLU(0.2)~ - Adds non-linearity with a Leaky ReLU activation.
Batch Norm 1: ~nn.BatchNorm1d(256, momentum=0.7)~ - Normalizes the 256 features to stabilize training.
Hidden Layer 2: ~nn.Linear(256, 512)~ - Increases the features from 256 to 512.
Hidden Layer 3: ~nn.LeakyReLU(0.2)~ - Another Leaky ReLU activation.
Batch Norm 2: ~nn.BatchNorm1d(512, momentum=0.7)~ - Normalizes the 512 features.
Hidden Layer 4: ~nn.Linear(512, 1024)~ - Further increases the features from 512 to 1024.
Hidden Layer 5: ~nn.LeakyReLU(0.2)~ - Another Leaky ReLU activation.
Batch Norm 3: ~nn.BatchNorm1d(1024, momentum=0.7)~ - Normalizes the 1024 features.
Output Layer: ~nn.Linear(1024, 784)~ - Outputs a 784-dimensional vector (flattened 28x28 image).
Output Activation: ~nn.Tanh()~ - Squashes the output to a range between -1 and 1.

*** using GPU

#+BEGIN_SRC python
# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
#+END_SRC

*** scaling images to original format
This code normalizes the tensors so that its pixel values range between 0 and 1

#+BEGIN_SRC python
# scale image back to (0, 1)
def scale_image(img):
  out = (img + 1) / 2
  return out
#+END_SRC

*** saving images
Here we create a folder to save the images generated by the model

#+BEGIN_SRC python
# Create a folder to store generated images
if not os.path.exists('/home/adrian/gan_images'):
  os.makedirs('/home/adrian/gan_images')
#+END_SRC

*** training
Training GANs is a bit different from previous model but we will cover the differences

#+BEGIN_SRC python
# Labels to use in the loop
ones_ = torch.ones(batch_size, 1).to(device)
zeros_ = torch.zeros(batch_size, 1).to(device)

# Save losses
d_losses = []
g_losses = []
#+END_SRC

- Initialize tensors `ones_` and `zeros_` with shapes `(batch_size, 1)`, filled with ones and zeros respectively, and move them to the specified device (CPU or GPU).
- Initialize lists `d_losses` and `g_losses` to store the discriminator and generator losses during training.

**** Epoch Loop
#+BEGIN_SRC python
for epoch in range(200):
  for inputs, _ in data_loader:
    # Reshape and move to GPU
    n = inputs.size(0)
    inputs = inputs.reshape(n, 784).to(device)

    # Set ones and zeros to correct size
    ones = ones_[:n]
    zeros = zeros_[:n]
#+END_SRC

- Loop over 200 epochs.
- Within each epoch, iterate over batches of inputs from `data_loader`.
- Reshape the inputs to a flat vector (784 dimensions for MNIST) and move them to the specified device.
- Adjust the size of the `ones` and `zeros` tensors to match the current batch size `n`.

**** Train Discriminator
#+BEGIN_SRC python
    ###########################
    ### Train discriminator ###
    ###########################

    # Real images
    real_outputs = D(inputs)
    d_loss_real = criterion(real_outputs, ones)

    # Fake images
    noise = torch.randn(n, latent_dim).to(device)
    fake_images = G(noise)
    fake_outputs = D(fake_images)
    d_loss_fake = criterion(fake_outputs, zeros)

    # Gradient descent step
    d_loss = 0.5 * (d_loss_real + d_loss_fake)
    d_optimizer.zero_grad()
    g_optimizer.zero_grad()
    d_loss.backward()
    d_optimizer.step()
#+END_SRC

- Real Images:
  - Pass the real images through the discriminator `D` to get `real_outputs`.
  - Compute the loss `d_loss_real` using `criterion` by comparing `real_outputs` with the `ones` tensor.
- Fake Images:
  - Generate random noise and pass it through the generator `G` to create fake images.
  - Pass these fake images through the discriminator to get `fake_outputs`.
  - Compute the loss `d_loss_fake` using `criterion` by comparing `fake_outputs` with the `zeros` tensor.
- Gradient Descent Step:
  - Compute the total discriminator loss `d_loss` as the average of `d_loss_real` and `d_loss_fake`.
  - Zero the gradients of both `d_optimizer` and `g_optimizer`.
  - Perform backpropagation on `d_loss` to compute the gradients.
  - Update the discriminator's parameters using `d_optimizer.step()`.

**** Train Generator
#+BEGIN_SRC python
    #######################
    ### Train generator ###
    #######################

    # Do it twice:
    for _ in range(2):
      # Fake images
      noise = torch.randn(n, latent_dim).to(device)
      fake_images = G(noise)
      fake_outputs = D(fake_images)

      # Reverse the labels!
      g_loss = criterion(fake_outputs, ones)

      # Gradient descent step
      d_optimizer.zero_grad()
      g_optimizer.zero_grad()
      g_loss.backward()
      g_optimizer.step()
#+END_SRC

- Train the Generator Twice:
  - Loop twice to train the generator more frequently.
  - Fake Images:
    - Generate random noise and pass it through the generator to create fake images.
    - Pass these fake images through the discriminator to get `fake_outputs`.
    - Compute the generator loss `g_loss` by comparing `fake_outputs` with the `ones` tensor (reversed labels).
  - Gradient Descent Step:
    - Zero the gradients of both `d_optimizer` and `g_optimizer`.
    - Perform backpropagation on `g_loss` to compute the gradients.
    - Update the generator's parameters using `g_optimizer.step()`.

- The rest we know.

#+BEGIN_SRC python
    # save losses
    d_losses.append(d_loss.item())
    g_losses.append(g_loss.item())


  ### print and save things ###
  print(f"Epoch: {epoch}, d_loss: {d_loss.item()}, g_loss: {g_loss.item()}")

  # PyTorch has a function to save a batch of images to file
  fake_images = fake_images.reshape(-1, 1, 28, 28)
  save_image(scale_image(fake_images), f"gan_images/{epoch+1}.png")
#+END_SRC

**** Training
- The training would look a bit like this:

#+BEGIN_SRC python
Epoch: 0, d_loss: 0.68047034740448, g_loss: 0.6662955284118652
Epoch: 1, d_loss: 0.7071035504341125, g_loss: 0.8107303380966187
Epoch: 2, d_loss: 0.6876696348190308, g_loss: 0.7310963869094849
Epoch: 3, d_loss: 0.6825389862060547, g_loss: 0.7769100069999695
Epoch: 4, d_loss: 0.6889893412590027, g_loss: 0.7556778788566589
Epoch: 5, d_loss: 0.682299017906189, g_loss: 0.7201077938079834
Epoch: 6, d_loss: 0.6838651895523071, g_loss: 0.740240752696991
Epoch: 7, d_loss: 0.6866905689239502, g_loss: 0.727881908416748
Epoch: 8, d_loss: 0.6904422044754028, g_loss: 0.6928049921989441
Epoch: 9, d_loss: 0.6933594942092896, g_loss: 0.7346236705780029
Epoch: 10, d_loss: 0.6938905715942383, g_loss: 0.722802996635437
Epoch: 11, d_loss: 0.6922292709350586, g_loss: 0.7095546126365662
Epoch: 12, d_loss: 0.6857796907424927, g_loss: 0.721759021282196
Epoch: 13, d_loss: 0.7025293111801147, g_loss: 0.7216035723686218
Epoch: 14, d_loss: 0.6925420761108398, g_loss: 0.7016552686691284
Epoch: 15, d_loss: 0.6858004927635193, g_loss: 0.7063485980033875
#+END_SRC

*** loss
- Plot loss

#+BEGIN_SRC python
plt.plot(g_losses, label='g_losses')
plt.plot(d_losses, label='d_losses')
plt.legend()
#+END_SRC

*** finished product
- At the end of the project the images created by the generator look very similar to the MNIST dataset.

#+BEGIN_SRC python
a = imread('gan_images/200.png')
plt.imshow(a)
#+END_SRC

(Images can be found in the images folders)

*** summary
Now

